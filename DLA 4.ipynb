{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1.\tHow would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
    "\n",
    "TensorFlow is an open-source library developed by Google primarily for deep learning applications. It also supports traditional machine learning. TensorFlow was originally developed for large numerical computations without keeping deep learning in mind. However, it proved to be very useful for deep learning development as well, and therefore Google open-sourced it.\n",
    "\n",
    "TensorFlow accepts data in the form of multi-dimensional arrays of higher dimensions called tensors. Multi-dimensional arrays are very handy in handling large amounts of data.\n",
    "TensorFlow works on the basis of data flow graphs that have nodes and edges. As the execution mechanism is in the form of graphs, it is much easier to execute TensorFlow code in a distributed manner across a cluster of computers while using GPUs.\n",
    "ensorFlow Offers Both C++ and Python API’s\n",
    "\n",
    "Before the development of libraries, the coding mechanism for machine learning and deep learning was much more complicated. This library provides a high-level API, and complex coding isn’t needed to prepare a neural network, configure a neuron, or program a neuron. The library completes all of these tasks. TensorFlow also has integration with Java and R.\n",
    "\n",
    "TensorFlow Supports Both CPUs and GPUs Computing Devices\n",
    "\n",
    "\n",
    "\n",
    "##2.\tIs TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "\n",
    "Python has a design philosophy that stresses allowing programmers to express concepts readably and in fewer lines of code. This philosophy makes the language suitable for a diverse set of use cases: simple scripts for web, large web applications (like YouTube), scripting language for other platforms (like Blender and Autodesk’s Maya), and scientific applications in several areas, such as astronomy, meteorology, physics, and data science.\n",
    "\n",
    "It is technically possible to implement scalar and matrix calculations using Python lists. However, this can be unwieldy, and performance is poor when compared to languages suited for numerical computation, such as MATLAB or Fortran, or even some general purpose languages, such as C or C++.\n",
    "\n",
    "To circumvent this deficiency, several libraries have emerged that maintain Python’s ease of use while lending the ability to perform numerical calculations in an efficient manner. Two such libraries worth mentioning are NumPy (one of the pioneer libraries to bring efficient numerical computation to Python) and TensorFlow (a more recently rolled-out library focused more on deep learning algorithms).\n",
    "\n",
    "•\tNumPy provides support for large multidimensional arrays and matrices along with a collection of mathematical functions to operate on these elements. The project relies on well-known packages implemented in other languages (like Fortran) to perform efficient computations, bringing the user both the expressiveness of Python and a performance similar to MATLAB or Fortran.\n",
    "\n",
    "•\tTensorFlow is an open-source library for numerical computation originally developed by researchers and engineers working at the Google Brain team. The main focus of the library is to provide an easy-to-use API to implement practical machine learning algorithms and deploy them to run on CPUs, GPUs, or a cluster.\n",
    "\n",
    "But how do these schemes compare? How much faster does the application run when implemented with NumPy instead of pure Python? What about TensorFlow? The purpose of this article is to begin to explore the improvements you can achieve by using these libraries.\n",
    "\n",
    "##3.\tDo you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
    "\n",
    "In TensorFlow the differences between constants and variables are that when you declare some constant, its value can't be changed in the future (also the initialization should be with a value, not with operation). Nevertheless, when you declare a Variable, you can change its value in the future with tf.\n",
    "\n",
    "##4.\tCan you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "A TensorFlow variable is the recommended way to represent shared, persistent state your program manipulates. This guide covers how to create, update, and manage instances of tf.Variable in TensorFlow.\n",
    "Variables are created and tracked via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like tf.keras use tf.Variable to store model parameters.\n",
    "Setup\n",
    "\n",
    "bool_variable=tf.Variable([False,False,False,True])\n",
    "\n",
    "complex_variable=tf.Variable([5+4j,6+1j])\n",
    "\n",
    "A variable looks and acts like a tensor, and, in fact, is a data structure backed by a tf.Tensor. Like tensors, they have a dtype and a shape, and can be exported to NumPy.\n",
    "\n",
    "print(\"Shape: \",my_variable.shape)\n",
    "\n",
    "print(\"DType: \",my_variable.dtype)\n",
    "\n",
    "print(\"As NumPy: \",my_variable.numpy())\n",
    "\n",
    "Shape:  (2, 2)\n",
    "DType:  <dtype: 'float32'>\n",
    "As NumPy:  [[1. 2.]\n",
    " [3. 4.]]\n",
    "Most tensor operations work on variables as expected, although variables cannot be reshaped.\n",
    "print(\"A variable:\",my_variable)\n",
    "print(\"\\nViewed as a tensor:\",tf.convert_to_tensor(my_variable))\n",
    "print(\"\\nIndex of highest value:\",tf.argmax(my_variable))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nCopying and reshaping: \",tf.reshape(my_variable,[1,4]))\n",
    "\n",
    "A variable: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
    "array([[1., 2.],\n",
    "       [3., 4.]], dtype=float32)>\n",
    "\n",
    "Viewed as a tensor: tf.Tensor(\n",
    "[[1. 2.]\n",
    " [3. 4.]], shape=(2, 2), dtype=float32)\n",
    "\n",
    "Index of highest value: tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
    "\n",
    "Copying and reshaping:  tf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n",
    "\n",
    "##5.\tA custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?\n",
    "\n",
    "Losses\n",
    "\n",
    "The purpose of loss functions is to compute the quantity that a model should seek to minimize during training.\n",
    "\n",
    "Available losses\n",
    "\n",
    "\n",
    "Probabilistic losses\n",
    "•\tBinaryCrossentropy class\n",
    "\n",
    "•\tCategoricalCrossentropy class\n",
    "\n",
    "•\tSparseCategoricalCrossentropy class\n",
    "\n",
    "•\tPoisson class\n",
    "\n",
    "•\tbinary_crossentropy function\n",
    "\n",
    "•\tcategorical_crossentropy function\n",
    "\n",
    "•\tsparse_categorical_crossentropy function\n",
    "\n",
    "•\tpoisson function\n",
    "\n",
    "•\tKLDivergence class\n",
    "\n",
    "•\tkl_divergence function\n",
    "\n",
    "Regression losses\n",
    "\n",
    "•\tMeanSquaredError class\n",
    "\n",
    "•\tMeanAbsoluteError class\n",
    "\n",
    "•\tMeanAbsolutePercentageError class\n",
    "\n",
    "•\tMeanSquaredLogarithmicError class\n",
    "\n",
    "•\tCosineSimilarity class\n",
    "\n",
    "•\tmean_squared_error function\n",
    "\n",
    "•\tmean_absolute_error function\n",
    "\n",
    "•\tmean_absolute_percentage_error function\n",
    "\n",
    "•\tmean_squared_logarithmic_error function\n",
    "\n",
    "•\tcosine_similarity function\n",
    "\n",
    "•\tHuber class\n",
    "\n",
    "\n",
    "Hinge losses for \"maximum-margin\" classification\n",
    "•\tHinge class\n",
    "\n",
    "•\tSquaredHinge class\n",
    "\n",
    "•\tCategoricalHinge class\n",
    "\n",
    "•\thinge function\n",
    "\n",
    "•\tsquared_hinge function\n",
    "\n",
    "•\tcategorical_hinge function\n",
    "\n",
    "\n",
    "##6.\tSimilarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?\n",
    "\n",
    "Keras metrics are functions that are used to evaluate the performance of your deep learning model. Choosing a good metric for your problem is usually a difficult task.\n",
    "\n",
    "•\tyou need to understand which metrics are already available in Keras and tf.keras and how to use them,\n",
    "\n",
    "•\tin many situations you need to define your own custom metric because the metric you are looking for doesn’t ship with Keras.\n",
    "\n",
    "•\tsometimes you want to monitor model performance by looking at charts like ROC curve or Confusion Matrix after every epoch.\n",
    "\n",
    "•\tIn Keras, metrics are passed during the compile stage as shown below. You can pass several metrics by comma separating them.\n",
    "\tfromkerasimport metrics\n",
    "\t\n",
    "\n",
    "\n",
    "##7.\tWhen should you create a custom layer versus a custom model?\n",
    "\n",
    "Introduction:\n",
    "Lambda layers are simple layers in TensorFlow that can be used to create some custom activation functions. But lambda layers have many limitations, especially when it comes to training these layers. So, the idea is to create custom layers that are trainable, using the inheritable Keras layers in TensorFlow — with a special focus on Dense layers.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "##8.\tWhat are some use cases that require writing your own custom training loop?\n",
    "\n",
    "Keras is a high level library, among all the other deep learning libraries, and we all love it for that. It abstracts most of the pain that, our not less beloved, Tensorflow brings with itself to crunch data very efficiently on GPU.\n",
    "\n",
    "I use Keras at work and for my personal projects and I am deeply in love with its API and approach to model building. But, what happens when you want to do something out-of-the-box? I will tell you, you stumble upon the framework. Which framework? The framework of the Keras paradigm. In Keras things are easy and pragmatic, you follow the steps and the things work amazingly well. But, if for whatever reason, you need to skip or detour from the main route, things start to get messy.\n",
    "\n",
    "You could argue: “but Keras is highly flexible, it has this amazing functional API for building daydream labyrinthic models, support for writing custom layers, the powerful Generators for handling Sequences, Images, multiprocessing, multi input-output, GPU parallelism and…”, I know and in fact, I know you know, or at least I expect it, otherwise, you would not be reading this post.\n",
    "\n",
    "But, in spite of this flexibility I could still point out some fairly annoying experiences in Keras such as loss functions with multiple inputs/parameters, loading saved models with custom layers… But somehow you can get that solved with some workarounds or by digging a bit into the code.\n",
    "\n",
    "However one of the things I struggled the most with is creating a custom training loop. But, why the heck do you want to build a custom training loop in the first place\n",
    "\n",
    "Reinforcement Learning mainly as far as I am concerned (let me know in the comments if you find others so I can learn too). The main reason to write this post is to clarify (or document if you prefer) the usage of certain tools in the Keras engine to build a custom training loop without being constrained strictly to the framework.\n",
    "\n",
    "##9.\tCan custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
    "In TensorFlow 2, eager execution is turned on by default. The user interface is intuitive and flexible (running one-off operations is much easier and faster), but this can come at the expense of performance and deployability.\n",
    "\n",
    "You can use tf.function to make graphs out of your programs. It is a transformation tool that creates Python-independent dataflow graphs out of your Python code. This will help you create performant and portable models, and it is required to use SavedModel.\n",
    "\n",
    "This guide will help you conceptualize how tf.function works under the hood, so you can use it effectively.\n",
    "\n",
    "The main takeaways and recommendations are:\n",
    "\n",
    "•\tDebug in eager mode, then decorate with @tf.function.\n",
    "\n",
    "•\tDon't rely on Python side effects like object mutation or list appends.\n",
    "\n",
    "•\ttf.function works best with TensorFlow ops; NumPy and Python calls are converted to constants.\n",
    "\n",
    "\n",
    "##10.\tWhat are the main rules to respect if you want a function to be convertible to a TF Function?\n",
    "\n",
    "tf.function creates polymorphic callables\n",
    "Internally, tf.types.experimental.GenericFunction may contain multiple tf.types.experimental.ConcreteFunctions, each specialized to arguments with different data types or shapes, since TensorFlow can perform more optimizations on graphs of specific shapes, dtypes and values of constant arguments. tf.function treats any pure Python values as opaque objects (best thought of as compile-time constants), and builds a separate tf.Graph for each set of Python arguments that it encounters. For more information, see the tf.function guide\n",
    "\n",
    "Executing a GenericFunction will select and execute the appropriate ConcreteFunction based on the argument types and values.\n",
    "To obtain an individual ConcreteFunction, use the GenericFunction.get_concrete_function method. It can be called with the same arguments as func and returns a tf.types.experimental.ConcreteFunction. ConcreteFunctions are backed by a single tf.Graph:\n",
    "\n",
    "\n",
    "Python numerical arguments should only be used when they take few distinct values, such as hyperparameters like the number of layers in a neural network.\n",
    "\n",
    "##11.\tWhen would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
    "\n",
    "Sequential and Functional APIs are declarative: first declare which layers are required and how they are connected. Data can be fed only after that. \n",
    "\n",
    "Model is a static graph of layers.\n",
    "\n",
    "Subclassing API allows an imperative programming style. Loops, varying shapes, conditional branching and other dynamic behaviors can be added.\n",
    "\n",
    "To use the Subclassing API:\n",
    "\n",
    "Subclass the keras.Model class.\n",
    "\n",
    "Create the layers you need in the constructor.\n",
    "\n",
    "Perform the computations in the call() method.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "High flexibility - anything can be done within the call() method.\n",
    "\n",
    "Models can be used as regular layers so they can be combined to build complex architectures.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Model architecture hidden in call() method so Keras cannot easily inspect, save or clone it.\n",
    "\n",
    "The summary() method only gives list of layers and no information about how they are connected to each other.\n",
    "\n",
    "Keras cannot check types and shapes ahead of time, so it is easier to make mistakes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
